{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc292508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "     Verifies data from hex maze session:\n",
    "         * All times must be consecutive and descending\n",
    "         * All trials must have the same target node\n",
    "         * Target node must not appear in the middle of a trial\n",
    "     Trials for which these conditions are not met is removed\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     data : df\n",
    "         pandas dataframe with rat info from one day\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas dataframe with suspicious or wrong trials removed\n",
    "\n",
    "    \"\"\"\n",
    "    from statistics import mode\n",
    "    import logging\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    \n",
    "    # Initiallize lists with log info and log errors to write to logfile at the end of the function\n",
    "    log_msg = []\n",
    "    log_error = []\n",
    "    \n",
    "    log_msg.append('\\n\\n----------------------------------------------------------------------------\\n')\n",
    "    log_msg.append('Data verification and removal of bad trials\\n')\n",
    "    log_msg.append('----------------------------------------------------------------------------\\n')\n",
    "\n",
    "    \n",
    "    # Initiallize list of bad_trials and determine target node for this session\n",
    "    bad_trials = []\n",
    "    tgt_node = mode(data.groupby('trial_no')['node'].last())\n",
    "        \n",
    "    # Check the times are all consecutive and descending\n",
    "    if ~(data['time'].sort_values().sort_index() == data['time'].sort_index()).all():\n",
    "        error_msg = 'ERROR: Times are not monotonically descending\\n'\n",
    "        print(error_msg)\n",
    "        log_error.append(error_msg)\n",
    "    \n",
    "    # Check consistency of derived values within each trial\n",
    "    # Within each trial, \n",
    "    for tr in data['trial_no'].unique():\n",
    "        this_trial = data.loc[data['trial_no'] == tr]\n",
    "        # check 'speed_ff' = 'distance' / 'seconds_ff'\n",
    "        speed = this_trial['distance'] / this_trial['seconds_ff']\n",
    "        if ~(this_trial[1:]['speed_ff'] == round(speed[1:], 3)).all():\n",
    "            error_msg = 'ERROR: Speed inconsistency found in trial '+ str(tr) +'\\n'\n",
    "            print(error_msg)\n",
    "            log_error.append(error_msg)\n",
    "            bad_trials.append(tr)\n",
    "\n",
    "        # Check 'seconds_ff' = time[x] - time[x-1]\n",
    "        seconds = (this_trial['time'] - this_trial['time'].shift(1)).dt.total_seconds()\n",
    "        if ~ (np.isclose(seconds[1:], this_trial[1:]['seconds_ff'], atol = 0.001)).all():\n",
    "            error_msg = 'ERROR: Time (seconds_ff) inconsistency found in trial '+ str(tr) +'\\n'\n",
    "            print(error_msg)\n",
    "            log_error.append(error_msg)\n",
    "            bad_trials.append(tr)\n",
    "                  \n",
    "    # Check that tgt node is the last node of every trial, and doesn't appear anywhere else\n",
    "    for tr in data['trial_no'].unique():\n",
    "        trial_nodes = data.loc[data['trial_no'] == tr, 'node']\n",
    "        if trial_nodes.iloc[-1] != tgt_node:\n",
    "            info_msg = 'ERROR: trial ' + str(tr) + ' does not end in target node ' + tgt_node + '\\n'\n",
    "            print(info_msg)\n",
    "            log_msg.append(info_msg)\n",
    "            bad_trials.append(tr)\n",
    "        if (trial_nodes.iloc[:-2] == tgt_node).any():\n",
    "            info_msg ='ERROR: trial ' + str(tr) + ' contains target node ' + tgt_node + ' in places other than last\\n'\n",
    "            print(info_msg)\n",
    "            log_msg.append(info_msg)\n",
    "            bad_trials.append(tr)\n",
    "\n",
    "    # Remove bad trials from dataframe\n",
    "    data_cl = data[~data['trial_no'].isin(bad_trials)]\n",
    "    info_msg = '\\nRemoved bad trials: ' + str(bad_trials) + '\\n'\n",
    "    print(info_msg)\n",
    "    log_msg.append(info_msg)\n",
    "    \n",
    "    \n",
    "    log_error_txt = ''.join(log_error)\n",
    "    log_info_txt = ''.join(log_msg)\n",
    "    logging.error(log_error_txt)\n",
    "    logging.info(log_info_txt)\n",
    "    \n",
    "    return(data_cl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede61981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_file(rat_filename, file_path = '../data/raw/'):\n",
    "    \"\"\"\n",
    "     Reads Rat HexMaze behavioural data from experiment logs.\n",
    "     Performs basic cleaning (removes duplicates)\n",
    "     Re-organises in a pandas-friendly format, and returns pandas dataframe.\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     arg1 : str\n",
    "         Filename of txt data with experimental logs for single rat\n",
    "     arg2 : str, optional\n",
    "         Path to where rat_filename is stored\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas dataframe with clean data\n",
    "\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import re # Regular expressions\n",
    "    import logging\n",
    "\n",
    "\n",
    "    #https://docs.python.org/3/howto/logging.html\n",
    "\n",
    "    # Extract exp. date and Rat Id from file name (format: Rat_HM_Ephys_RatX_ratcode_YYYYMMDD.txt)\n",
    "    # Info in filename is separated by '_'. Split parts accordingly:\n",
    "    filename_info = rat_filename.split('_')\n",
    "    # Exp date is last element in filename, but contains also .txt which we remove by splitting again\n",
    "    exp_date = pd.to_datetime(filename_info[-1].split('.')[0]).date()\n",
    "    rat_no = filename_info[3]\n",
    "    rat_id = filename_info[4]\n",
    "    info_msg = 'Importing data from ' + rat_no + ' on ' + exp_date.strftime('%Y-%m-%d') + ' ('+ rat_filename + ')'\n",
    "    print(info_msg + ':')\n",
    "    \n",
    "    log_msg = []\n",
    "    \n",
    "    log_msg.append('\\n\\n=========================================================================\\n')\n",
    "    log_msg.append(info_msg)\n",
    "    log_msg.append('\\n---------------------------------------------------------------------------\\n')\n",
    "    \n",
    "\n",
    "    # Extract fileinfo to list_all\n",
    "    with open(file_path + rat_filename, 'r') as f:\n",
    "        # Load all lines from file\n",
    "        list_all = [x for k,x in enumerate(f.readlines())]\n",
    "\n",
    "    # Locate trial line boundaries and first trial line\n",
    "    list_tr_bb = [n for n, x in enumerate(list_all) if re.match(r'^Summary Trial', x)]\n",
    "    trial_headers = [x for n, x in enumerate(list_all) if re.match(r'^Summary Trial', x)]\n",
    "\n",
    "    # Add a final entry to list_tr_bb to mark end boundary of last trial\n",
    "    list_tr_bb.append(len(list_all))\n",
    "\n",
    "    info_msg = str(len(list_tr_bb)) + ' trials found initially\\n'\n",
    "    print(info_msg)\n",
    "    log_msg.append(info_msg)\n",
    "\n",
    "\n",
    "\n",
    "    ### DATA CLENANING\n",
    "    # Data files contain duplicate lines and/or duplicate trials\n",
    "    # Find and remove them\n",
    "\n",
    "    # Look for duplicate trials to write info to log\n",
    "    dupe_trials = [x for n, x in enumerate(trial_headers) if x in trial_headers[:n]] # Get duplicate trial headers\n",
    "\n",
    "    info_msg = str(len(dupe_trials)) + ' duplicate trials found\\n'\n",
    "    log_msg.append(info_msg)\n",
    "    [log_msg.append('Trial ' + x.split()[2] + '\\n') for x in dupe_trials]\n",
    "    print(info_msg)\n",
    "    [print('Trial ' + x.split()[2]) for x in dupe_trials]\n",
    "\n",
    "\n",
    "    # Look for duplicate lines in general and remove them from list_all\n",
    "    dupe_lines = [n for n, x in enumerate(list_all) if x in list_all[:n]]\n",
    "\n",
    "    # Remove duplicate lines from list_all\n",
    "    info_msg = str(len(dupe_lines)) + ' duplicate lines found\\n'\n",
    "    print(info_msg)\n",
    "    log_msg.append(info_msg)\n",
    "\n",
    "    for x in sorted(dupe_lines, reverse=True):\n",
    "        del list_all[x]\n",
    "\n",
    "    # Update trial boundaries after deletions\n",
    "    list_tr_bb = [n for n, x in enumerate(list_all) if re.match(r'^Summary Trial', x)]\n",
    "    list_tr_bb.append(len(list_all))\n",
    "\n",
    "    # Strip extraneous strings from file lines, and read data within each line into list of lists of strings\n",
    "    list_sess = []\n",
    "    for l,tr in enumerate(list_tr_bb[:-1]): \n",
    "        # Find all lines starting with ( between trial boundaries\n",
    "        list_sing = [x for x in list_all[list_tr_bb[l]:list_tr_bb[l+1]] if x[0]=='('] # Lines starting with ( \n",
    "        # Remove parenthesis, commas and '' from string\n",
    "        list_sing = [x.replace(\"(\", \"\") for x in list_sing]\n",
    "        list_sing = [x.replace(\")\", \"\") for x in list_sing]\n",
    "        list_sing = [x.replace(\",\", \"\") for x in list_sing]\n",
    "        list_sing = [x.replace(\"'\", \"\") for x in list_sing]\n",
    "        list_sing = [x.replace(\"\\n\", \"\") for x in list_sing]\n",
    "        # Now separate data in each line within the trial\n",
    "        list_sing = [x.split(sep=' ') for x in list_sing]\n",
    "        list_sess.append(list_sing)\n",
    "\n",
    "    info_msg = 'Final number of trials loaded: ' + str(len(list_sess)) + '\\n'\n",
    "    log_msg.append(info_msg)\n",
    "    print(info_msg)\n",
    "    \n",
    "    ## TRANSFORM TO 'LONG' FORMAT AND SAVE IN PANDAS DATA FRAME\n",
    "    # Transform current 'wide' data format into 'long' format, and store as a pandas \n",
    "    # dataframe.\n",
    "    # Edge trajectory data will be re-ordered into a successive list of nodes and times.\n",
    "    # Additional data, such as seconds, distance, and speed refers to the trajectory from\n",
    "    # node[i-1] to node[i], being zero for the inital row.\n",
    "\n",
    "    # First re-order and store as single lists for each variable\n",
    "    # Variables with _ff suffix  (\"from file\") can be computed from other primary variables in the file. \n",
    "    # Suffix is included in case these vars need to be re-computed \n",
    "\n",
    "    # List size: total no. of lines (across all trials\n",
    "    # with one additional line per trial to flatten structure\n",
    "    # also discount empty trials in case there are any\n",
    "    size = sum([len(x) for x in list_sess]) + len(list_sess) - list_sess.count([])                                                # with one additional line per trial (25 trials in total) to flatten structure\n",
    "    trial_no = [None]*size \n",
    "    distance = [None]*size \n",
    "    seconds_ff = [None]*size # seconds from file \n",
    "    nodes = [None]*size #np.zeros(size, dtype=int) # nodes the rat passes through (flat)\n",
    "    speed_ff = [None]*size #np.zeros(size)\n",
    "    times = [None]*size #np.zeros(shape) # all timestamps (flat)\n",
    "    rat_no_col = [rat_no]*size\n",
    "    rat_id_col = [rat_id]*size\n",
    "    exp_date_col = [exp_date]*size\n",
    "\n",
    "\n",
    "    line_no = 0 # initialize counter\n",
    "\n",
    "    for tr, trial in enumerate(list_sess):\n",
    "        # First check if the trial is empty (An empty trial was found for Rat8 on 20210618)\n",
    "        if(trial) == []:\n",
    "            info_msg = '***Trial ' + str(tr+1) + ' is empty ****\\n'\n",
    "            log_msg.append(info_msg)\n",
    "            continue\n",
    "\n",
    "        # Add inital trial line for nodes and timestamps array with starting node (first value of first line in the trial)\n",
    "        trial_no[line_no] = tr+1\n",
    "        nodes[line_no] = trial[0][0] # First value from first row in that trial: start node\n",
    "        times[line_no] = trial[0][2] # Third value from first row in that trial: start time\n",
    "        # times[:, cum_line_no] = [float(x) for x in time_list]\n",
    "        # Initialize distance and seconds\n",
    "        distance[line_no] = 0\n",
    "        seconds_ff[line_no] = 0\n",
    "        speed_ff[line_no] = 0\n",
    "        line_no +=1\n",
    "\n",
    "        for row in trial:\n",
    "\n",
    "            trial_no[line_no] = tr+1\n",
    "            nodes[line_no] = row[1]\n",
    "            times[line_no] = row[3]\n",
    "            seconds_ff[line_no] = row[4]\n",
    "            distance[line_no] = row[5]\n",
    "            speed_ff[line_no] = row[6]     \n",
    "            line_no += 1\n",
    "\n",
    "\n",
    "    ## BUILD PD DATA FRAME\n",
    "\n",
    "    data = pd.DataFrame(list(zip(rat_id_col, rat_no_col, exp_date_col, trial_no, nodes, times, distance, seconds_ff, speed_ff)),\n",
    "                       columns = ['rat_id', 'rat_no', 'date', 'trial_no', 'node', 'time', 'distance', \\\n",
    "                                  'seconds_ff', 'speed_ff'])\n",
    "    # Set appropriate data types for each column. Times data set to timedelta object,\n",
    "    # although maybe it would better be just a time? (day data is not relevant in our case)\n",
    "    data[\"distance\"] = data[\"distance\"].astype('float')\n",
    "    data[\"seconds_ff\"] = data[\"seconds_ff\"].astype('float')\n",
    "    data[\"speed_ff\"] = data[\"speed_ff\"].astype('float')\n",
    "    data[\"time\"] = pd.to_timedelta(data[\"time\"])\n",
    "\n",
    "    \n",
    "    log_txt = ''.join(log_msg)\n",
    "    logging.info(log_txt)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c31f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enrich_data(data):\n",
    "#     \"\"\"\n",
    "#      Adds useful columns for posterior rat analysis:\n",
    "#          * Within-trial cumulative seconds\n",
    "#          * Within-trial cumulative speed\n",
    "#          * Island name at each step\n",
    "#          * Boolean u_turn column\n",
    "#          * Boolean re-visted column\n",
    "#          * Shortest distance to target at each step\n",
    "#          * Actual distance to target according to path taken by rat\n",
    "\n",
    "#      Parameters\n",
    "#      ----------\n",
    "#      data : df\n",
    "#          pandas dataframe with rat info from one day\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pandas dataframe with additional columns\n",
    "\n",
    "#     \"\"\"\n",
    "#     import pandas as pd\n",
    "#     import numpy as np\n",
    "#     import networkx as nx # Package for graph represenations \n",
    "\n",
    "    \n",
    "#     # Set trial number as index for easy selecting trials\n",
    "#     data.set_index('trial_no', inplace=True)\n",
    "\n",
    "#     # Set appropriate data types for each column. Times data set to timedelta object,\n",
    "#     # although maybe it would better be just a time? (day data is not relevant in our case)\n",
    "#     data[\"distance\"] = data[\"distance\"].astype('float')\n",
    "#     data[\"seconds_ff\"] = data[\"seconds_ff\"].astype('float')\n",
    "#     data[\"speed_ff\"] = data[\"speed_ff\"].astype('float')\n",
    "#     data[\"times\"] = pd.to_timedelta(data[\"times_ff\"])\n",
    "\n",
    "\n",
    "#     # Add column with cumulative distance and cumulative seconds\n",
    "#     data[\"cum_distance\"] = \"\"\n",
    "#     data[\"cum_seconds\"] = \"\"\n",
    "#     for tr in range(1, len(list_sess)):\n",
    "#         data.loc[tr, \"cum_distance\"] = data.loc[tr, \"distance\"].cumsum()\n",
    "#         data.loc[tr, \"cum_seconds\"] = data.loc[tr, \"seconds_ff\"].cumsum()\n",
    "\n",
    "#     # Add column with node classification    \n",
    "#     data[\"island\"] = \"\"\n",
    "#     data.loc[data[\"node\"].astype('int') // 100 == 1, \"island\"] = 'Ireland'\n",
    "#     data.loc[data[\"node\"].astype('int') // 100 == 2, \"island\"] = 'Japan'\n",
    "#     data.loc[data[\"node\"].astype('int') // 100 == 3, \"island\"] = 'Hawaii'\n",
    "#     data.loc[data[\"node\"].astype('int') // 100 == 4, \"island\"] = 'Easter I.'\n",
    "\n",
    "#     # Detect u_turns: moments when current node is the same as 2 nodes ago.\n",
    "#     # Store as a boolean column to the main datafrmae\n",
    "#     data['u_turn'] = (data['node'] == data['nodes'].shift(2))\n",
    "\n",
    "#     data['re-visited'] = False\n",
    "\n",
    "#     for tr in data.index.unique():\n",
    "#         dup_nodes = data.loc[tr, 'node'].duplicated()\n",
    "#         data.loc[tr, 're-visited'] = dup_nodes\n",
    "\n",
    "#     data[data['re-visited'] == True] \\\n",
    "#                 [['node', 'speed_ff']]\n",
    "\n",
    "#     data['act_stps_2trgt'] = np.nan\n",
    "#     data['min_stps_2trgt'] = np.nan\n",
    "\n",
    "#     ## BUILD A MAZE REPRESENTATION: (maybe this should be a different function)\n",
    "#     # Load hexMaze graph and compute shortest paths\n",
    "\n",
    "#     print(\"load graph\")\n",
    "#     G = nx.read_edgelist(edgelist_filename)  \n",
    "#     print(\"graph: number of nodes = \",G.number_of_nodes(),\", edges = \",G.number_of_edges())\n",
    "\n",
    "#     ### pre-compute all possible shortest path lengths and save in dictionary (does not save shortest paths itself)\n",
    "#     DD = nx.shortest_path_length(G) \n",
    "#     DD = dict(DD)\n",
    "#     print(\"dictionary: len =\", len(DD), \", total items =\", sum([len(dv) for dv in DD.values()]))\n",
    "\n",
    "#     for tr in data.index.unique():\n",
    "#         # Number of steps taken by rat in the trial (trajectory lenght):\n",
    "#         traj_len = len(data.loc[tr, 'node'])\n",
    "\n",
    "#         # Number of steps still left until rat reaches target, at each node passed:\n",
    "#         act_stps_2trgt = [traj_len-n for n in range(1, traj_len+1)]\n",
    "\n",
    "#         # Target node\n",
    "#         tgt_node = data.loc[tr, 'node'].iloc[-1]\n",
    "#         # Minimum number of steps until target at each node passed by rat\n",
    "#         min_stps_2trgt = [DD[str(a_node)][tgt_node] for a_node in data.loc[tr, 'nodes']]\n",
    "\n",
    "#         data.loc[tr, 'act_stps_2trgt'] = act_stps_2trgt\n",
    "#         data.loc[tr, 'min_stps_2trgt'] = min_stps_2trgt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
